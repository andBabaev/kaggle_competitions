{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meduim.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "f92347c49f922ab32adb7e6cf84abe4282f7434f",
        "colab_type": "text",
        "id": "1JrlR2pVbp2t"
      },
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"../../img/ods_stickers.jpg\" />\n",
        "    \n",
        "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
        "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
      ]
    },
    {
      "metadata": {
        "_uuid": "b599ca68ba8dff27c63319b4327d486762797850",
        "id": "nxFpWDevbekz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## <center>Assignment #6\n",
        "### <center> Beating baselines in \"How good is your Medium article?\"\n",
        "    \n",
        "<img src='../../img/medium_claps.jpg' width=40% />\n",
        "\n",
        "\n",
        "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"A6 baseline\" (~1.45 Public LB score). Do not forget about our shared [\"primitive\" baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline) - you'll find something valuable there.\n",
        "\n",
        "**Your task:**\n",
        " 1. \"Freeride\". Come up with good features to beat the baseline \"A6 baseline\" (for now, public LB is only considered)\n",
        " 2. You need to name your [team](https://www.kaggle.com/c/how-good-is-your-medium-article/team) (out of 1 person) in full accordance with the [course rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q). You can think of it as a part of the assignment. 16 credits for beating the mentioned baseline and correct team naming.\n",
        " \n",
        "*For discussions, please stick to [ODS Slack](https://opendatascience.slack.com/), channel #mlcourse_ai, pinned thread __#a6__*"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1193ef5d19c4b8bdafc245406885e18ea6b3308",
        "id": "YhZmlt1Hbek0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73eacb91b4a70aa5e38649fa10c250f7ab819021",
        "id": "YA6sB6xBbek5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import json\n",
        "from tqdm import tqdm_notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "25a9727a01526f34c3e20cdec5a52739649e9bca",
        "id": "kZXepZ1Dbek9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following code will help to throw away all HTML tags from an article content."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43b7f8f5bfa4e4b348a2d5db203fdc284dce9080",
        "id": "THCnYTm9bek_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from html.parser import HTMLParser\n",
        "\n",
        "class MLStripper(HTMLParser):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "        self.strict = False\n",
        "        self.convert_charrefs= True\n",
        "        self.fed = []\n",
        "    def handle_data(self, d):\n",
        "        self.fed.append(d)\n",
        "    def get_data(self):\n",
        "        return ''.join(self.fed)\n",
        "\n",
        "def strip_tags(html):\n",
        "    s = MLStripper()\n",
        "    s.feed(html)\n",
        "    return s.get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ed09dd5870f921e657907809e2add90a7c4def1f",
        "id": "fAfck-O7belC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Supplementary function to read a JSON line without crashing on escape characters."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9933311bf1443b299538eb967099a214780273f2",
        "id": "sXGg9W4AbelD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_json_line(line=None):\n",
        "    result = None\n",
        "    try:        \n",
        "        result = json.loads(line)\n",
        "    except Exception as e:      \n",
        "        # Find the offending character index:\n",
        "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
        "        # Remove the offending character:\n",
        "        new_line = list(line)\n",
        "        new_line[idx_to_replace] = ' '\n",
        "        new_line = ''.join(new_line)     \n",
        "        return read_json_line(line=new_line)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "603b4a15ce6ec6548da948e8704c09b62b66642b",
        "id": "fBTuq8CubelG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "18c24b57c0c6d37e385681ea94922cd6131d9540",
        "id": "6cB8x1b_belI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_description(path_to_data,\n",
        "                               inp_filename, is_train=True):\n",
        "    \n",
        "    prefix = 'train' if is_train else 'test'\n",
        "    \n",
        "    with open(os.path.join(path_to_data, inp_filename), \n",
        "              encoding='utf-8') as inp_json_file:\n",
        "        \n",
        "        f = open(os.path.join(path_to_data, '{}_description.txt'.format(prefix)), 'w', encoding='utf-8')\n",
        "        print(os.path.join(path_to_data, '{}_description.txt'.format(prefix)))\n",
        "        for line in tqdm_notebook(inp_json_file):\n",
        "            json_data = read_json_line(line)\n",
        "            f.write(strip_tags(json_data['meta_tags']['twitter:description'].replace('\\n', ' ').replace('\\r', ' ')) + '\\n')\n",
        "            \n",
        "        f.close()\n",
        "\n",
        "#extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "ed3a15abce31c7adc501c69632619b8cf908d7fb",
        "id": "SP7Fl7tkbelL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "extract_description(r'C:\\Users\\Андрей\\AnacondaProjects\\ODS\\mlcourse.ai\\data\\kaggle_medium', 'train.json', is_train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7bf8473ea176540eaed76717bd06341c281aa4d0",
        "id": "sOYYa5i-belP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_features_and_write(path_to_data,\n",
        "                               inp_filename, is_train=True):\n",
        "    \n",
        "    features = ['content', 'published', 'title', 'author']\n",
        "    prefix = 'train' if is_train else 'test'\n",
        "    feature_files = [open('{}_{}.txt'.format(prefix, feat),\n",
        "                          'w', encoding='utf-8')\n",
        "                     for feat in features]\n",
        "    \n",
        "    with open(os.path.join(path_to_data, inp_filename), \n",
        "              encoding='utf-8') as inp_json_file:\n",
        "\n",
        "        for line in tqdm_notebook(inp_json_file):\n",
        "            json_data = read_json_line(line)\n",
        "            \n",
        "            feature_files[0].write(strip_tags(json_data['content'].replace('\\n', ' ').replace('\\r', ' ')) + '\\n')\n",
        "            feature_files[1].write(json_data['published']['$date'].split('.')[0] + '\\n')\n",
        "            feature_files[2].write(strip_tags(json_data['title'].replace('\\n', ' ').replace('\\r', ' ')) + '\\n')\n",
        "            feature_files[3].write(strip_tags(json_data['author']['url'].split('@')[-1]) + '\\n')\n",
        "            \n",
        "    feature_files[0].close()\n",
        "    feature_files[1].close()\n",
        "    feature_files[2].close()\n",
        "    feature_files[3].close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "988b0073c89b014c28180d22db6f75b32d5f6a21",
        "id": "M7o1wVZQbelT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_DATA = r'../input' # modify this if you need to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "00c907b0f73924155cf3e926a9f29b3e8f59ecce",
        "id": "dCp72XsabelY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "990cb90b6ea3e71ae5cb42eb015849f886acc961",
        "id": "K5-6wS_Abelb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3e533d5c88d0a35b33d64d62aeb3525e0fbb3acd",
        "id": "h8Kzhkiwbele",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Add the following groups of features:**\n",
        "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
        "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
        "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
        "    - Bag of authors (i.e. One-Hot-Encoded author names)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0652d55b6aeead9e7d1276e3805882a808d884ce",
        "id": "k6It4VHybelf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1,2), max_features=100000) \n",
        "with open('train_title.txt', encoding='utf-8') as input_train_file:\n",
        "    X_train_title_sparse = vect.fit_transform(input_train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fe7b55e9534911936af23f230aedddd80b79cb2",
        "id": "nHFhyfMPbeli",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#vect = CountVectorizer(ngram_range=(1,2), max_features=100000) \n",
        "with open('test_title.txt', encoding='utf-8') as input_train_file:\n",
        "    X_test_title_sparse = vect.transform(input_train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e14d12daf2bfb2d7068e5ec6b16f63ecd13e8008",
        "id": "u2ps4KiSbell",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vect_c = TfidfVectorizer(ngram_range=(1,2), max_features=150000) \n",
        "with open('train_content.txt', encoding='utf-8') as input_train_file:\n",
        "    X_train_content_sparse = vect_c.fit_transform(input_train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "962089c9b4d6ecec7b2671d4aca89c2ce614b70d",
        "id": "L_72Zmudbelp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('test_content.txt', encoding='utf-8') as input_train_file:\n",
        "    X_test_content_sparse = vect_c.transform(input_train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3abc12122e7393ffe8e98398690f2ce037b043d0",
        "id": "jbyKCiBTbels",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_date_f(PATH_TO_DATA, pub_filename, tit_filename):\n",
        "    date_list = []\n",
        "    with open(pub_filename) as f:\n",
        "        for line in f:\n",
        "            date_list.append(pd.to_datetime(line.split('.')[0], format='%Y-%m-%dT%H:%M:%S'))\n",
        "    date_df = pd.DataFrame(date_list, columns=['date'])\n",
        "    \n",
        "    date_df['start_hour'] = date_df['date'].apply(lambda x: x.hour)\n",
        "    hour = date_df['start_hour'].values\n",
        "    date_df['morning'] = ((hour >= 7) & (hour <= 11)).astype('int')\n",
        "    date_df['day'] = ((hour >= 12) & (hour <= 18)).astype('int')\n",
        "    date_df['evening'] = ((hour >= 19) & (hour <= 23)).astype('int')\n",
        "    date_df['night'] = ((hour >= 0) & (hour <= 6)).astype('int')\n",
        "    date_df['weekday'] = date_df['date'].apply(lambda ts: ts.dayofweek).astype('int64') \n",
        "    date_df['is_weekend'] = date_df['date'].apply(lambda x: 1 if x.date().weekday() in (5, 6) else 0)\n",
        "    \n",
        "    date_df = pd.concat((date_df, pd.get_dummies(date_df[['weekday', 'start_hour']], \n",
        "                                             columns=['start_hour', 'weekday'])), axis=1)\n",
        "    date_df.head()\n",
        "    \n",
        "    with open(tit_filename, encoding='utf-8') as input_train_file:\n",
        "        len_tit = []\n",
        "        for i in input_train_file:\n",
        "            len_tit.append(len(i))\n",
        "    #date_df['len_title'] = np.array(len_tit)\n",
        "    \n",
        "    return date_df.drop(['date', 'weekday', 'start_hour'], axis=1).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fef4dd3ee240cc991d7bb2d0986eb769a60d958c",
        "id": "-OObf2Qpbelw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_time_features_sparse = extract_date_f(PATH_TO_DATA, 'train_published.txt', 'train_title.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "754c98e11e5c8919706293e2ca4f8e815e1e613a",
        "id": "kQaDa_lqbel2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_time_features_sparse = extract_date_f(PATH_TO_DATA, 'test_published.txt', 'test_title.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb5656c7d4b21c6fbb166f3c5bd08792825479fe",
        "id": "UwAk7sUCbel8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('train_author.txt', encoding='utf-8') as input_train_file:\n",
        "    author1 = []\n",
        "    for i in input_train_file:\n",
        "        author1.append(i)\n",
        "print(len(set(author1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05aba23f304e9ac60529af13c65a074499446362",
        "id": "F0BRNmF4bemA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('test_author.txt', encoding='utf-8') as input_train_file:\n",
        "    author2 = []\n",
        "    for i in input_train_file:\n",
        "        author2.append(i)\n",
        "print(len(set(author2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "0bdd3122b2f08f39394b3e85e355ed5bc39533db",
        "id": "YflgJeE1bemE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = pd.get_dummies(author1 + author2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c19b150dfb057afe21c28fe2107023c3b76f78b",
        "id": "Jyhd-oh3bemG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "94dd44e72428becbb47e3027eedcef32b65a3124",
        "id": "6g04UYlRbemJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Join all sparse matrices.**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5b48cb1eb764dc61f73936ccb6f46d4dd56e35a",
        "id": "VNcb7h_pbemK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_tmp_scaled = StandardScaler().fit_transform(X_train_time_features_sparse)\n",
        "test_tmp_scaled = StandardScaler().fit_transform(X_test_time_features_sparse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "a462042087d7f61267ad0bfd875ba633bd74bfd9",
        "id": "hSkFE1zQbemN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_sparse = hstack([\n",
        "                        X_train_content_sparse,\n",
        "                         X_train_title_sparse, \n",
        "                         train_tmp_scaled, \n",
        "                         a.values[:len(author1), :]\n",
        "]).tocsr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90951e27fd96a65e389758a11fb4c45a98fa31ff",
        "id": "A1Mr5nfKbemQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_sparse = hstack([\n",
        "                        X_test_content_sparse,\n",
        "                         X_test_title_sparse, \n",
        "                         test_tmp_scaled, \n",
        "                         a.values[len(author1):, :],\n",
        "]).tocsr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e22fa2e10729afa5efb34c179e339cef861fda34",
        "id": "ES9o4a3vbemS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "df694cacd37b0c1f53523fb93b3b2a949f92b131",
        "id": "tHFjfvgkbemV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Read train target and split data for validation.**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8d1cc91fbbff29f08d73860c0c3ae0d3e213c32",
        "id": "k3ydaTeXbemW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d_ = {name: [] for name in ['id','log_recommends']}\n",
        "with open(os.path.join('../input', 'train_log1p_recommends.csv'))as file:\n",
        "    for i, line in tqdm_notebook(enumerate(file)):\n",
        "        if not i:\n",
        "            continue\n",
        "        r = line.replace('\\n', '').split(',')\n",
        "        d_['id'].append(r[0])\n",
        "        d_['log_recommends'].append(r[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73359cf5f2b66f92966ac65b7b5266f4463ffb99",
        "id": "kYUaEXAybema",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_target = pd.DataFrame(d_['log_recommends'], d_['id'], ['log_recommends'])\n",
        "train_target.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "4f5e9a06b8eaa1d18f96e9a1ffe3ad9afe6ab469",
        "id": "DK_CyZ52beme",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = train_target['log_recommends'].values.astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fecf7b9bced2ef75d4a46340f96a5879c420d46f",
        "id": "qeJOgLDsbemh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_part_size = int(0.7 * train_target.shape[0])\n",
        "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
        "y_train_part = y_train[:train_part_size]\n",
        "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
        "y_valid = y_train[train_part_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa4e9b38316ae88fcec1e48b95dedc2e5ce5553b",
        "id": "8w55gF88bemk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train a simple Ridge model and check MAE on the validation set.**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b5634815c283879b1de4e6330d9a155d57e1714",
        "id": "mLUpIuXubemk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha=1, random_state=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2c1a060ebb4953c3cb2847adfc143eadbad5c77",
        "id": "xDhzlW0Fbemn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ridge.fit(X_train_part_sparse, y_train_part);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "82b7168940a9af7220ea751a2da2cab5a24ca398",
        "id": "95hVP3MGbemp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ridge_pred = ridge.predict(X_valid_sparse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "47368ecb6c49f9171d80467f6b147b662446ad1c",
        "id": "7sg8JgNXbemt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ridge_valid_mae = mean_absolute_error(y_valid, ridge_pred)\n",
        "ridge_valid_mae"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d288ff1059edecf6d4c07b6258e98fec05df3dab",
        "id": "5ftK8dl9bemv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f81f98bc8ae34735b8808eb12b1479197e3e8d00",
        "id": "LWKUAJpFbemw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ridge.fit(X_train_sparse, y_train);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e36c9e8fb276f0ae60762d036b425b086db056b8",
        "id": "tqXFHIYobemy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ridge_test_pred = ridge.predict(X_test_sparse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af9d3c6e9ea48104442396982272a19fd7f2f47d",
        "id": "B2RHMQSybem2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def write_submission_file(prediction, filename,\n",
        "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
        "                                                      'sample_submission.csv')):\n",
        "    #submission = pd.read_csv(path_to_sample, index_col='id')\n",
        "    d_ = {name: [] for name in ['id','log_recommends']}\n",
        "    with open(path_to_sample)as file:\n",
        "        for i, line in tqdm_notebook(enumerate(file)):\n",
        "            if not i:\n",
        "                continue\n",
        "            r = line.replace('\\n', '').split(',')\n",
        "            d_['id'].append(r[0])\n",
        "            d_['log_recommends'].append(r[1])\n",
        "    df_ = pd.DataFrame(d_['log_recommends'], d_['id'], ['log_recommends'])\n",
        "    df_['log_recommends'] = prediction\n",
        "    df_.index.name = 'id'\n",
        "    df_.to_csv(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75673cb4b99e68b1ae7944f72ca462857c761a52",
        "id": "1wF-TGsnbem5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "write_submission_file(ridge_test_pred + (4.33328 - mean_absolute_error(ridge_test_pred, np.zeros_like(ridge_test_pred))), \n",
        "                      'assignment6_medium_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd6045137f03727ee469aa9657c1d97f64abf344",
        "id": "GNpd8X--bem7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14b8aa6f94471cb5ce428965a19f700abde36a1e",
        "id": "DE4qQFo6benA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}